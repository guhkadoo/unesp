\chapter{Problema}
\label{c.problema}

%A compressão de dados é uma técnica essencial para otimizar a utilização de recursos computacionais e melhorar a transmissão de informações, principalmente em ambientes de grande volume de dados. Existem diversos algoritmos clássicos de compressão, como o Huffman, LZ77, LZW e GZIP, amplamente utilizados em sistemas de armazenamento, comunicação de dados e aplicações web. No entanto, a escolha do algoritmo de compressão mais adequado depende de fatores como o tipo de dado a ser comprimido, a eficiência da compressão e o tempo de execução.

O problema a ser investigado neste trabalho é: "Como os diferentes algoritmos clássicos de compressão de dados (Huffman, LZ77, LZW, GZIP) se comparam em termos de eficiência de compressão e tempo de execução, e qual é o impacto dessas variáveis em aplicações práticas?". A pesquisa busca analisar como o desempenho desses algoritmos varia dependendo do tipo de dado a ser comprimido (como texto, imagem e áudio) e qual algoritmo oferece o melhor equilíbrio entre eficiência e tempo de processamento em diferentes cenários.

A hipótese inicial que orienta este estudo é que os algoritmos clássicos de compressão apresentam diferenças significativas em termos de tempo de execução e taxa de compressão, dependendo do tipo de dado e da aplicação específica. Por exemplo, o GZIP pode ser mais eficiente em termos de tempo de execução, enquanto o Huffman pode ser mais eficaz em termos de compressão de arquivos de texto. No entanto, a escolha do algoritmo deve ser feita levando em consideração as necessidades específicas de cada aplicação, como a necessidade de compressão rápida em tempo real ou a maximização da taxa de compressão em arquivos grandes.

A delimitação deste estudo inclui a análise de algoritmos de compressão sem perdas (lossless), com foco nos quatro algoritmos clássicos mencionados, aplicados a três tipos principais de dados: arquivos de texto, imagens em formato PNG e pequenos arquivos de áudio. A pesquisa não incluirá algoritmos de compressão com perdas (lossy), como JPEG e MP3, ou algoritmos adaptativos modernos, como Brotli ou Zstandard.

Este problema é relevante, pois a escolha do algoritmo de compressão adequado tem um impacto direto no desempenho de sistemas de armazenamento e comunicação de dados, afetando, por exemplo, a velocidade de transferência de arquivos em redes e a eficiência no uso de recursos de armazenamento em nuvem. Além disso, a análise comparativa permitirá uma compreensão mais aprofundada das vantagens e limitações de cada algoritmo em diferentes cenários de uso.

A pesquisa será viável por meio da implementação prática dos algoritmos selecionados e da realização de experimentos de compressão, medindo tanto a eficiência em termos de taxa de compressão quanto o tempo de execução. Será possível gerar conclusões sobre qual algoritmo se destaca em cada tipo de dado e qual oferece o melhor desempenho global em diferentes cenários.


